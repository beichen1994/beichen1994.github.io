---
title: 机器学习之决策树
date: 2020-01-13 12:07:37
tags:
- machine learning
categories: 
- Computer
---

#### sklearn建模流程
* 实例化，建立评估模型对象
* 通过模型接口训练模型
* 通过模型接口评估模型

#### 工作原理
根据数据的特征和标签总结出决策规则，并用树状图的结构来表示出来。


#### 节点
根节点：针对特征的判断
中间节点：针对特征的判断
叶子节点:对应具体的类别标签

#### 要解决的问题
* 如何从数据表中找出最佳节点和最佳分支
* 如何让决策树停止生长，防止过拟合

#### sklean中的决策树
|  |  |
| --- | --- |
| tree.DecisionTreeClassifier | 分类树 |
| tree.DecisionTreeRegressor |  回归树|
| tree.export_graphviz|将决策树导出为DOT格式，画图专用|
|tree.ExtraTreeClassifier|高随机版本的分类树|
|tree.ExtraTreeRegressor|高随机版本的回归树|

```python
from sklearn import tree

clf = tree.DecisionTreeclassfier()
clf = clf.fit(X_train,y_train)
result = clf.score(X_test,y_test)
```
#### DecisionTreeClassifier

##### criterion(不纯度)

不纯度越低，决策树对训练集的拟合越好。
叶子结点的不纯度一定是低于父节点。

对于不纯度的计算有两种方法
* 信息熵(Entropy)
$$Entropy(t)=-\sum_{i=0}^{c-1}p(i|t)log_{2}p(i|t)$$
* 基尼系数(Gini Impurity)
$$Gini(t)=1-\sum_{i=0}^{c-1}p(i|t)^2$$

其中$p(i|t)$代表分类i在节点t上所占的比例

#### 基本流程
* 计算全部特征的不纯度指标
* 选取不纯度指标最优的特征来分枝
* 在第一个特征的分枝下，计算全部特征的不纯度指标
* 选取不纯度指标最优的特征来分支
以此类推，直至没有特征可用


建立一棵树
```python
from sklearn import tree
from sklearn.datasets import load_wine 
from sklearn.model_selection import train_test_split
```

```python
wine = load_wine()
wine.data
wine.target
wine.feature_names
wine.target_names
```

```python
#组合数据
import pandas as pd 
pd.concat([p.DataFrame(wine.data),pd.DataFrame(wine.target)],axis=1)
```
```python
#按照30%划分训练集与测试集
X_train,X_test,Y_train,Y_test = train_test_split(wine.data,wine.target,test_size = 0.3)
```
```python
#实例化
clf = tree.DecisionTreeClassfier(criterion='entropy)
clf = clf.fit(X_train,Y_train)
score = clf.score(X_test,Y_test)
score
```

```python
#画树
feature_name = ['酒精','苹果酸','灰','灰的碱性','镁','总酚','类黄酮','非黄烷类酚类','花青素','颜色强度','色调','od280/od315西施葡萄酒','脯氨酸']
import graphviz
dot_data = tree.export_graphviz(clf
                                ,feature_names = feature_name
                                ,class_names=['琴酒','雪莉','贝尔摩德']
                                ,rounded=True)

graph = graphviz.Source(dot_data)
graph
```

```python
#特征重要性
clf = feature_importances_
[*zip(feature_name,clf.feature_importances_)]
```




