---
title: 机器学习之评价标准
date: 2019-12-25 16:53:03
tags:
- machine learning
categories: 
- Computer
---

&ensp;&ensp;哈喽，大家好，我们又见面了！我们在判断一种机器学习算法的性能好坏时，需要根据一定的评价标准。

&ensp;&ensp;对于分类算法来说，有以下标准：

* 分类准确度:
    分类准确度是通过计算预测正确的值```np.sum(y_predict==y_test)```在实际的结果值```len(y_test)```中所占的比率。但是对于极度偏斜的数据，只用分类准确度还远远不够。

* 混淆矩阵(Confusion Matrix):

    |  |0 | 1 | 
    | --- | --- | --- |
    | 0 | TN | FP | 
    | 1 | FN | TP |

        其中行的0、1代表真实值，列的0、1代表预测值
        TN(True Negative):判定值为假，真实值与之相同
        FP(False Positive):判定值为真，真实值与之相反
        FN(False Negative):判定值为假，真实值与之相反
        TP(True Positive):判定值为真，真实值与之相同

* 精准率(查准率):

$$precision = \frac{TP}{TP+FP}$$

    表示预测为正的样本中多少是真的样本

* 召回率(查全率):

$$recall = \frac{TP}{TP+FN}$$

    表示样本的正例中有多少被预测正确了

* F1 score

$$\frac{1}{F1}=\frac{1}{2}(\frac{1}{precision}+\frac{1}{recall})$$
$$F1 = \frac{2precision*recall}{precision+recall}$$

    同时兼顾精准率和召回率

* Precision-Recall的平衡

* Precision-Recall曲线

* ROC曲线(Receiver Operation characteristic Curve)

$$TPR = \frac{TP}{TP+FN} = Recall$$
$$FPR = \frac{FP}{TN+FP}$$
    
    描述TPR和FPR之间的关系



***
&ensp;&ensp;我们在前面说到，我们的误差函数一般都是误差的平方，如$$ \sum_{i=1}^{m}(y_{test}^{i} - y_{test}^{'i})^2 $$这种形式。我们还在线性回归那一节中使用最小二乘法推导了该误差函数的最小化的参数。
***
&ensp;&ensp;我们都知道，误差函数的值越小越好，根据这个误差函数，我们又有了相似的误差函数形式。如

* 均方误差 MSE(Mean Squared Error)

$$MSE=\frac{1}{m}\sum_{i=1}^{m}(y_{test}^{i}-y_{test}^{'i})^2$$

* 均方根误差 RMSE(Root Mean Squared Error)

$$RMSE=\sqrt{\frac{1}{m}\sum_{i=1}^{m}(y_{test}^{i}-y_{test}^{'i})^2}=\sqrt{MSE}$$

* 平方绝对误差 MAE(Mean Absolute Error)

$$MSE=\frac{1}{m}\sum_{i=1}^{m}\|y_{test}^{i}-y_{test}^{'i}\|$$

&ensp;&ensp;此外，我们还有一种回归算法评价标准

* $R^2$

$$
R^2=1-\frac{SS_{residual}}{SS_{total}}
$$
$$
=1-\frac{\sum_{i}(y^{'i}-y^{i})^2}{\sum_{i}(\overline{y}-y^{i})^2}
$$
$$
=1-\frac{\sum_{i}(y^{'i}-y^{i})^2/m}{\sum_{i}(\overline{y}-y^{i})^2/m}
$$
$$
=1-\frac{MSE(y^{'},y)}{Var(y)}
$$

其中$SS_{residual}$是Residual Sum of Square，$SS_{total}$是Total sum of Square。$\sum_{i}(y^{'i}-y^{i})^2$是使用我们的模型产生的一些错误，而 $\sum_{i}(\overline{y}-y^{i})^2$是使用$y=\overline{y}$预测产生的错误，这是一个baseline model，会产生非常多的错误。如果$R^2<0$，说明我们的模型还不如基准模型，因此，$R^2$越大越好，$R^2$值为1时，我们的模型则百分之百正确。


